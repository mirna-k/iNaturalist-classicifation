{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGglW4-tr3bC"
      },
      "source": [
        "# Klasifikacija rijetkih biljaka i životinja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8pNpmZlr3bE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import json\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from imageio.v2 import imread\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/mirna-k/iNaturalist-classicifation.git"
      ],
      "metadata": {
        "id": "yxuhXIkgsIeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QId7JGfGr3bE"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-2uYL_Dur3bF"
      },
      "outputs": [],
      "source": [
        "class MatchedDataset(Dataset):\n",
        "  def __init__(self, dataset_dir, class_label_map_json):\n",
        "    self.dataset_dir = dataset_dir\n",
        "\n",
        "    with open(class_label_map_json, 'r') as f:\n",
        "        self.class_label_map = json.load(f)\n",
        "\n",
        "    self.groups = {}\n",
        "    self.size = 0\n",
        "\n",
        "    # Populate groups dictionary with class labels as keys and image paths as values\n",
        "    for class_name, label in self.class_label_map.items():\n",
        "        class_dir = os.path.join(dataset_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            image_paths = [os.path.join(class_dir, filename) for filename in os.listdir(class_dir)]\n",
        "            self.groups[label] = image_paths\n",
        "            self.size += len(image_paths)\n",
        "\n",
        "    self.classes = list(self.groups.keys())\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    cls0 = random.choice(self.classes)\n",
        "    image0_idx = random.randint(0, len(self.groups[cls0]) - 1)\n",
        "    image0 = self.groups[cls0][image0_idx]\n",
        "    ## select random label, 1 for same class, 0 for different class\n",
        "    label = random.randint(0,1)\n",
        "    if label:\n",
        "        ## select a different image of the same class\n",
        "        while True:\n",
        "            image1_idx = random.randint(0, len(self.groups[cls0]) - 1)\n",
        "            if image0_idx != image1_idx:\n",
        "                image1 = self.groups[cls0][image1_idx]\n",
        "                break\n",
        "    else:\n",
        "        ## select a random image from a different class\n",
        "        while True:\n",
        "            cls1 = random.choice(self.classes)\n",
        "            if cls0 != cls1:\n",
        "                image1 = random.choice(self.groups[cls1])\n",
        "                break\n",
        "\n",
        "    return image0, image1, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matched_dataset = MatchedDataset('iNaturalist-classicifation/iNaturalist dataset', 'iNaturalist-classicifation/label_map.json')\n",
        "\n",
        "image0, image1, label = matched_dataset[0]  # Get the first sample in the dataset\n",
        "\n",
        "print(\"Image 0:\", image0)\n",
        "print(\"Image 1:\", image1)\n",
        "print(\"Label:\", label)"
      ],
      "metadata": {
        "id": "_cRNvE0fr_o2",
        "outputId": "b026c398-ad9c-4afe-a4eb-e634fce0ea3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 0: iNaturalist-classicifation/iNaturalist dataset/Fratercula arctica/fratercula_003.png\n",
            "Image 1: iNaturalist-classicifation/iNaturalist dataset/Fratercula arctica/fratercula_001.png\n",
            "Label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tyLMzprr3bF"
      },
      "source": [
        "## Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNDTn-F6r3bF"
      },
      "outputs": [],
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.fc = nn.Linear(base_model.fc.in_features, 128)\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        x = self.base_model(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dvCXfYzr3bF"
      },
      "outputs": [],
      "source": [
        "# TODO: prilagoditi funkciju datasetu\n",
        "\n",
        "class FewShotDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5Qatuxdr3bG"
      },
      "outputs": [],
      "source": [
        "# TODO: proučiti i doraditi funkciju po uzoru na labose\n",
        "\n",
        "def train_few_shot(model, dataloader, optimizer, criterion, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            img1, img2, label = data\n",
        "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
        "\n",
        "            output1, output2 = model(img1, img2)\n",
        "            loss = criterion(output1, output2, label)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Epoch {}, Batch {}, Loss: {:.4f}'.format(epoch, batch_idx, loss.item()))\n",
        "\n",
        "        print('Epoch {}, Average Loss: {:.4f}'.format(epoch, total_loss / len(dataloader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCd8o72Ur3bG"
      },
      "outputs": [],
      "source": [
        "# TODO: podijeliti na train i eval funkcije\n",
        "# TODO: optimizator, loss, dataset ...\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load pre-trained ResNet model\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "base_model = nn.Sequential(*list(resnet.children())[:-1])  # Remove the final fully connected layer\n",
        "\n",
        "# Initialize Siamese network\n",
        "siamese_model = SiameseNetwork(base_model)\n",
        "siamese_model.to(device)\n",
        "\n",
        "# Define your criterion, optimizer, and other hyperparameters\n",
        "criterion = nn.TripletMarginLoss()\n",
        "optimizer = optim.Adam(siamese_model.parameters(), lr=0.001)\n",
        "\n",
        "# Example dataset - you should replace this with your own dataset\n",
        "# Here, data is assumed to be a list of tuples (image, label)\n",
        "data = [(torch.randn(3, 224, 224), random.randint(0, 9)) for _ in range(100)]\n",
        "\n",
        "# TODO: augmentacija dataseta --> dodati u funk za dataset\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_data = data[:80]\n",
        "test_data = data[80:]\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = FewShotDataset(train_data, transform=transform)\n",
        "test_dataset = FewShotDataset(test_data, transform=transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Train the model\n",
        "train_few_shot(siamese_model, train_dataloader, optimizer, criterion, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "# (You can implement evaluation logic similarly to training logic, using test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-SxQNUTr3bG"
      },
      "outputs": [],
      "source": [
        "# TODO: tensorboard za vizualizaciju + dodatne funkcije po potrebi"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}