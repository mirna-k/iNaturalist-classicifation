{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikacija rijetkih biljaka i životinja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data, DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v2 import imread\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def label_dataset(dataset_dir, label_map_path):\n",
    "\n",
    "    with open(label_map_path, \"r\") as f:\n",
    "        class_label_map = json.load(f)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_dir = os.path.join(dataset_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            \n",
    "            label = class_label_map[class_name]\n",
    "            \n",
    "            for image_file in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_file)\n",
    "                \n",
    "                image = Image.open(image_path)\n",
    "                \n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedDataset(Dataset):\n",
    "  def __init__(self, original_dataset):\n",
    "    self.grouped = {}\n",
    "    self.size = len(original_dataset)\n",
    "    for i, c in original_dataset:\n",
    "      if c not in self.grouped:\n",
    "        self.grouped[c] = []\n",
    "      self.grouped[c].append(i)\n",
    "\n",
    "    self.classes = list(self.grouped.keys())\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    cls0 = random.choice(self.classes)\n",
    "    image0_idx = random.randint(0, len(self.grouped[cls0]) - 1)\n",
    "    image0 = self.grouped[cls0][image0_idx]\n",
    "    ## select random label, 1 for same class, 0 for different class\n",
    "    label = random.randint(0,1)\n",
    "    if label:\n",
    "      ## select a different image of the same class\n",
    "      while True:\n",
    "        image1_idx = random.randint(0, len(self.grouped[cls0]) - 1)\n",
    "        if image0_idx != image1_idx:\n",
    "          image1 = self.grouped[cls0][image1_idx]\n",
    "          break\n",
    "    else:\n",
    "      ## select a random image from a different class\n",
    "      while True:\n",
    "        cls1 = random.choice(self.classes)\n",
    "        if cls0 != cls1:\n",
    "          image1 = random.choice(self.grouped[cls1])\n",
    "          break\n",
    "\n",
    "    return image0, image1, label\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.fc = nn.Linear(base_model.fc.in_features, 128)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: prilagoditi funkciju datasetu\n",
    "\n",
    "class FewShotDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: proučiti i doraditi funkciju po uzoru na labose\n",
    "\n",
    "def train_few_shot(model, dataloader, optimizer, criterion, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            img1, img2, label = data\n",
    "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss = criterion(output1, output2, label)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Epoch {}, Batch {}, Loss: {:.4f}'.format(epoch, batch_idx, loss.item()))\n",
    "\n",
    "        print('Epoch {}, Average Loss: {:.4f}'.format(epoch, total_loss / len(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: podijeliti na train i eval funkcije\n",
    "# TODO: optimizator, loss, dataset ...\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pre-trained ResNet model   \n",
    "resnet = models.resnet18(pretrained=True)\n",
    "base_model = nn.Sequential(*list(resnet.children())[:-1])  # Remove the final fully connected layer\n",
    "\n",
    "# Initialize Siamese network\n",
    "siamese_model = SiameseNetwork(base_model)\n",
    "siamese_model.to(device)\n",
    "\n",
    "# Define your criterion, optimizer, and other hyperparameters\n",
    "criterion = nn.TripletMarginLoss()\n",
    "optimizer = optim.Adam(siamese_model.parameters(), lr=0.001)\n",
    "\n",
    "# Example dataset - you should replace this with your own dataset\n",
    "# Here, data is assumed to be a list of tuples (image, label)\n",
    "data = [(torch.randn(3, 224, 224), random.randint(0, 9)) for _ in range(100)]\n",
    "\n",
    "# TODO: augmentacija dataseta --> dodati u funk za dataset\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_data = data[:80]\n",
    "test_data = data[80:]\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = FewShotDataset(train_data, transform=transform)\n",
    "test_dataset = FewShotDataset(test_data, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Train the model\n",
    "train_few_shot(siamese_model, train_dataloader, optimizer, criterion, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "# (You can implement evaluation logic similarly to training logic, using test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tensorboard za vizualizaciju + dodatne funkcije po potrebi"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
